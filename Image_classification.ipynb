{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import skimage.io as io\n",
    "from torchvision import datasets\n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "from skimage.util import random_noise\n",
    "from skimage.filters import gaussian\n",
    "from torchvision import models\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training model\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # (1) conv.layer 1\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 6, kernel_size = 5)\n",
    "        self.conv1_bn = nn.BatchNorm2d(6)\n",
    "        # (2) conv.layer 2\n",
    "        self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 8, kernel_size = 5)\n",
    "        self.conv2_bn = nn.BatchNorm2d(8)\n",
    "        # (3) conv.layer 3\n",
    "        self.conv3 = nn.Conv2d(in_channels = 8, out_channels = 11, kernel_size = 3)\n",
    "        self.conv3_bn = nn.BatchNorm2d(11)\n",
    "        # (4) conv.layer 4\n",
    "        self.conv4 = nn.Conv2d(in_channels = 11, out_channels = 13, kernel_size = 3)\n",
    "        self.conv4_bn = nn.BatchNorm2d(13)\n",
    "        # (5) conv.layer 5\n",
    "        self.conv5 = nn.Conv2d(in_channels = 13, out_channels = 15, kernel_size = 3)\n",
    "        self.conv5_bn = nn.BatchNorm2d(15)\n",
    "        \n",
    "        # (1) fully connected layer 1\n",
    "        self.fc1 = nn.Linear(in_features=15*25*25, out_features=3000)\n",
    "        self.fc1_bn = nn.BatchNorm1d(3000)\n",
    "        # (2) fully connected layer 2\n",
    "        self.fc2 = nn.Linear(in_features=3000, out_features=500)\n",
    "        self.fc2_bn = nn.BatchNorm1d(500)\n",
    "        \n",
    "        # output layer\n",
    "        self.out = nn.Linear(in_features=500, out_features=7)\n",
    "\n",
    "    def forward(self, t):\n",
    "        \n",
    "        #conv. layers\n",
    "        t = self.conv1(t)\n",
    "        t = self.conv1_bn(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        t = self.conv2(t)\n",
    "        t = self.conv2_bn(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        t = self.conv3(t)\n",
    "        t = self.conv3_bn(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        #conv4 and conv5 layer do not have maxpool to improve accuracy\n",
    "        t = self.conv4(t)\n",
    "        t = self.conv4_bn(t)\n",
    "        t = F.relu(t)\n",
    "                \n",
    "        t = self.conv5(t)\n",
    "        t = self.conv5_bn(t)\n",
    "        t = F.relu(t)\n",
    "                \n",
    "        #linear layers\n",
    "        t = t.reshape(-1, 15 *25 * 25)\n",
    "        t = self.fc1(t)\n",
    "        t = self.fc1_bn(t)\n",
    "        t = F.relu(t)\n",
    "       \n",
    "        t = self.fc2(t)\n",
    "        t = self.fc2_bn(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        #output layer\n",
    "        t = self.out(t)\n",
    "        t = F.softmax(t, dim=1)\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading dataset of images\n",
    "train_set=datasets.ImageFolder(root=r'C:\\Users\\Rushikesh J. Metkar\\Desktop\\Acads\\GNR638\\train\\train', transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ]), target_transform=None, is_valid_file=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network().cuda()\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=5, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmentation of dataset\n",
    "\n",
    "lists=[]\n",
    "for i in range(560):\n",
    "    temp=[train_set[i][0],train_set[i][1]]\n",
    "    lists.append(temp)\n",
    "    for j in range(1,12):\n",
    "        #rotating each image in the dataset by an angle which is mutiple of 30degree\n",
    "        images=rotate(np.transpose(temp[0].numpy(), (1, 2, 0)) , angle = 30*j, mode = 'wrap')\n",
    "        images=torch.tensor(np.transpose(images,(2 , 0 , 1)))\n",
    "        lists.append([images,temp[1]])\n",
    "    \n",
    "    #shifting each image in the dataset by (25px,25px)\n",
    "    transform = AffineTransform(translation=(25,25))\n",
    "    wrapShift1 = warp(np.transpose(temp[0].numpy(), (1, 2, 0)) , transform , mode='wrap')\n",
    "    wrapShift1 = torch.tensor(np.transpose(wrapShift1,(2 , 0 , 1)))\n",
    "    lists.append([wrapShift1,temp[1]])\n",
    "    \n",
    "    #shifting each image in the dataset by (-25px,-25px)\n",
    "    transform = AffineTransform(translation=(-25,-25))\n",
    "    wrapShift2 = warp(np.transpose(temp[0].numpy(), (1, 2, 0)) , transform , mode='wrap')\n",
    "    wrapShift2 = torch.tensor(np.transpose(wrapShift2 , (2 , 0 , 1)))\n",
    "    lists.append([wrapShift2,temp[1]])\n",
    "    \n",
    "    # I've not used blurring of images as it blurrs the markings of the basketball and tennis courts and the model doesn't\n",
    "    # distinguish between the two \n",
    "    # Also since most of the images are symmetrical, did not flip the images for augmentation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training_dataset\n",
    "\n",
    "Training_dataset = torch.utils.data.DataLoader(lists, batch_size = 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1160.432070851326\n",
      "1\n",
      "1058.5934487581253\n",
      "2\n",
      "1023.8758972883224\n",
      "3\n",
      "1004.796567440033\n",
      "4\n",
      "993.2620408535004\n",
      "5\n",
      "985.7865858078003\n",
      "6\n",
      "978.0725890398026\n",
      "7\n",
      "970.0047948360443\n",
      "8\n",
      "966.1873159408569\n",
      "9\n",
      "956.9965070486069\n",
      "10\n",
      "955.9949917793274\n",
      "11\n",
      "950.3593146800995\n",
      "12\n",
      "947.8977760076523\n",
      "13\n",
      "941.7905030250549\n",
      "14\n",
      "935.4961730241776\n",
      "15\n",
      "935.6714873313904\n",
      "16\n",
      "934.9468305110931\n",
      "17\n",
      "935.1481719017029\n",
      "18\n",
      "934.3316670656204\n",
      "19\n",
      "930.4808365106583\n",
      "20\n",
      "930.6399060487747\n",
      "21\n",
      "929.304603934288\n",
      "22\n",
      "927.9039134979248\n",
      "23\n",
      "925.7532404661179\n",
      "24\n",
      "924.167882680893\n",
      "25\n",
      "923.7262268066406\n",
      "26\n",
      "924.4387308359146\n",
      "27\n",
      "921.0095748901367\n",
      "28\n",
      "920.0617240667343\n",
      "29\n",
      "921.4118163585663\n",
      "30\n",
      "920.178387761116\n",
      "31\n",
      "919.5169363021851\n",
      "32\n",
      "920.5306876897812\n",
      "33\n",
      "920.6465982198715\n",
      "34\n",
      "919.0524392127991\n",
      "35\n",
      "919.2364993095398\n",
      "36\n",
      "919.1665225028992\n",
      "37\n",
      "919.5062716007233\n",
      "38\n",
      "918.6611522436142\n",
      "39\n",
      "918.7990086078644\n",
      "40\n",
      "918.0694148540497\n",
      "41\n",
      "917.2836139202118\n",
      "42\n",
      "917.2286076545715\n",
      "43\n",
      "917.466367483139\n",
      "44\n",
      "917.729948759079\n",
      "45\n",
      "917.7942723035812\n",
      "46\n",
      "916.0277420282364\n",
      "47\n",
      "916.56312084198\n",
      "48\n",
      "916.2574936151505\n",
      "49\n",
      "916.9247524738312\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "\n",
    "optimizer = optim.SGD(network.parameters(), lr=0.008, momentum = 0.5)\n",
    "for epoch in range(50): #50 no. of epochs\n",
    "    total_loss=0\n",
    "    total_preds = 0\n",
    "    for batch in Training_dataset:\n",
    "        images, labels = batch\n",
    "        optimizer.zero_grad()                                                  # assining the gradients value 0\n",
    "        preds = network(images.cuda())                                         # Pass Batch\n",
    "        loss = F.cross_entropy(preds, labels.cuda())                           # Calculate Loss\n",
    "        loss.backward()                                                        # Calculate Gradients\n",
    "        optimizer.step()                                                       # Update Weights\n",
    "        total_loss += loss.item()                                              # Calculating total loss \n",
    "        total_preds += preds.argmax(dim=1).eq(labels.cuda()).sum().item()      # Calculating total no. of correct preditions   \n",
    "    print(epoch)\n",
    "    print(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing dataset\n",
    "\n",
    "test_set = datasets.ImageFolder(root=r'C:\\Users\\Rushikesh J. Metkar\\Desktop\\Acads\\GNR638\\test_set1', transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ]), target_transform=None, is_valid_file=None)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 4, 3, 2, 3], device='cuda:0')\n",
      "tensor([6, 1, 4, 0, 5], device='cuda:0')\n",
      "tensor([3, 1, 6, 3, 3], device='cuda:0')\n",
      "tensor([6, 1, 5, 4, 3], device='cuda:0')\n",
      "tensor([3, 0, 4, 2, 4], device='cuda:0')\n",
      "tensor([1, 3, 3, 5, 2], device='cuda:0')\n",
      "tensor([3, 3, 6, 5, 0], device='cuda:0')\n",
      "tensor([1, 4, 3, 0, 0], device='cuda:0')\n",
      "tensor([3, 6, 3, 0, 3], device='cuda:0')\n",
      "tensor([3, 5, 6, 2, 5], device='cuda:0')\n",
      "tensor([5, 0, 2, 3, 1], device='cuda:0')\n",
      "tensor([2, 4, 3, 3, 6], device='cuda:0')\n",
      "tensor([3, 0, 2, 1, 5], device='cuda:0')\n",
      "tensor([3, 1, 0, 6, 2], device='cuda:0')\n",
      "tensor([3, 4, 3, 0, 2], device='cuda:0')\n",
      "tensor([3, 1, 5, 2, 0], device='cuda:0')\n",
      "tensor([6, 1, 1, 4, 5], device='cuda:0')\n",
      "tensor([6, 1, 4, 2, 3], device='cuda:0')\n",
      "tensor([4, 3, 5, 0, 3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#calculating predictions with batch_size = 5\n",
    "\n",
    "for i in test_loader:\n",
    "    my_image,label = i\n",
    "    prediction = network(my_image.cuda())\n",
    "    print(prediction.argmax(dim = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels of the test_set to check accuracy\n",
    "\n",
    "label_test_set = [6,3,3,2,3,6,1,3,3,5,3,1,6,3,3,6,1,5,4,3,3,3,4,3,4,3,3,3,5,2,1,3,6,5,3,0,3,3,0,3,3,3,1,4,3,1,5,0,2,5,5,4,2,3,0,2,6,3,3,6,3,4,2,1,3,3,3,0,6,2,3,4,3,6,2,3,1,5,2,3,0,1,1,4,5,6,3,4,2,3,4,3,5,0,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(69, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "label_test_set = torch.tensor(np.array(label_test_set))\n",
    "\n",
    "#Concatenating the preditions and counting the total no of correct predictions\n",
    "\n",
    "result = torch.tensor([])       #\n",
    "for batch in test_loader:\n",
    "    image1,label1 = batch\n",
    "    prediction = network(image1.cuda())\n",
    "    result = torch.cat((result.cuda(), prediction.argmax(dim=1)))\n",
    "    \n",
    "print(torch.eq(label_test_set.cuda(), result).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = np.zeros(95)\n",
    "for i in range(95):\n",
    "    if result[i] == 3:\n",
    "        final_result[i] = 7\n",
    "    if result[i] == 2:\n",
    "        final_result[i] = 3\n",
    "    if result[i] == 1:\n",
    "        final_result[i] = 2\n",
    "    if result[i] == 0:\n",
    "        final_result[i] = 1\n",
    "    if result[i] == 4:\n",
    "        final_result[i] = 4\n",
    "    if result[i] == 5:\n",
    "        final_result[i] = 6\n",
    "    elif result[i] == 6:\n",
    "        final_result[i] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(95):\n",
    "    if label_test_set[i] == 3:\n",
    "        label_test_set[i] = 7\n",
    "    if label_test_set[i] == 2:\n",
    "        label_test_set[i] = 3\n",
    "    if label_test_set[i] == 1:\n",
    "        label_test_set[i] = 2\n",
    "    if label_test_set[i] == 0:\n",
    "        label_test_set[i] = 1\n",
    "    if label_test_set[i] == 4:\n",
    "        label_test_set[i] = 4\n",
    "    if label_test_set[i] == 5:\n",
    "        label_test_set[i] = 6\n",
    "    elif label_test_set[i] == 6:\n",
    "        label_test_set[i] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ImageID  Label\n",
      "0      1001      5\n",
      "1      1002      7\n",
      "2      1003      7\n",
      "3      1004      3\n",
      "4      1005      7\n",
      "..      ...    ...\n",
      "90     1091      4\n",
      "91     1092      7\n",
      "92     1093      6\n",
      "93     1094      1\n",
      "94     1095      1\n",
      "\n",
      "[95 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#converting to csv file\n",
    "\n",
    "import pandas as pd\n",
    "final_result = final_result.astype(int)\n",
    "a = {'ImageID': range(1001, 1096), 'Label': final_result}\n",
    "b = pd.DataFrame(a)\n",
    "print(b)\n",
    "\n",
    "b.to_csv('19D070034_gnr2.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'C:\\Users\\Rushikesh' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 6, 252, 252]             456\n",
      "       BatchNorm2d-2          [-1, 6, 252, 252]              12\n",
      "            Conv2d-3          [-1, 8, 124, 124]             440\n",
      "       BatchNorm2d-4          [-1, 8, 124, 124]              16\n",
      "            Conv2d-5           [-1, 11, 60, 60]             803\n",
      "       BatchNorm2d-6           [-1, 11, 60, 60]              22\n",
      "            Conv2d-7           [-1, 13, 28, 28]           1,300\n",
      "       BatchNorm2d-8           [-1, 13, 28, 28]              26\n",
      "            Conv2d-9           [-1, 15, 26, 26]           1,770\n",
      "      BatchNorm2d-10           [-1, 15, 26, 26]              30\n",
      "           Linear-11                 [-1, 3000]      30,423,000\n",
      "      BatchNorm1d-12                 [-1, 3000]           6,000\n",
      "           Linear-13                  [-1, 500]       1,500,500\n",
      "      BatchNorm1d-14                  [-1, 500]           1,000\n",
      "           Linear-15                    [-1, 7]           3,507\n",
      "================================================================\n",
      "Total params: 31,938,882\n",
      "Trainable params: 31,938,882\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 8.66\n",
      "Params size (MB): 121.84\n",
      "Estimated Total Size (MB): 131.25\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(network, (3,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
